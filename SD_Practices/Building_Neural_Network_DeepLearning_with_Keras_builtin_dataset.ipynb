{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7ee42fd7-6246-4dd7-b09e-4ee2d0c0ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.datasets import boston_housing #Importing the building datasets to be used\n",
    "\n",
    "from sklearn import preprocessing #To help in processing the training and testing dateset  \n",
    "\n",
    "from keras.models import Sequential #This helps to crate a model\n",
    "\n",
    "from keras.layers import Dense #Dense is the name of the layers we would be using today\n",
    "\n",
    "from keras.optimizers import RMSprop #imported to help \n",
    "\n",
    "from keras.callbacks import EarlyStopping #This is used for the callback, i.e to stop inputs going through other hidden layers after mision is achived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bdd557-1443-4faa-b7ca-dc2d9a47b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Note, Keras do have 2 backend it can use, one is the Tensoflow, the other is Theano.\n",
    "### This backends, are import we know when working on a project with keras\n",
    "### The check the backend here\n",
    "\n",
    "from keras import backend as bk\n",
    "bk.backend() #As below, i prints Tensorflow, telling thats the backend we are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66c4ec7f-f9b0-44b9-bd09-19caab99fc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57026/57026 [==============================] - 0s 5us/step\n"
     ]
    }
   ],
   "source": [
    "# Now lets import the boston_housing dataset\n",
    "\n",
    "(x_train, y_train) , (x_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e8da544-f2b2-4fd5-bbae-0421fdf7e135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.23247e+00, 0.00000e+00, 8.14000e+00, ..., 2.10000e+01,\n",
       "        3.96900e+02, 1.87200e+01],\n",
       "       [2.17700e-02, 8.25000e+01, 2.03000e+00, ..., 1.47000e+01,\n",
       "        3.95380e+02, 3.11000e+00],\n",
       "       [4.89822e+00, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01,\n",
       "        3.75520e+02, 3.26000e+00],\n",
       "       ...,\n",
       "       [3.46600e-02, 3.50000e+01, 6.06000e+00, ..., 1.69000e+01,\n",
       "        3.62250e+02, 7.83000e+00],\n",
       "       [2.14918e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
       "        2.61950e+02, 1.57900e+01],\n",
       "       [1.43900e-02, 6.00000e+01, 2.93000e+00, ..., 1.56000e+01,\n",
       "        3.76700e+02, 4.38000e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1622553c-cfb7-4802-a961-fa81c4e4559f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,\n",
       "       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,\n",
       "       32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,\n",
       "       23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,\n",
       "       12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,\n",
       "       22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,\n",
       "       15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,\n",
       "       14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,\n",
       "       14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,\n",
       "       28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,\n",
       "       19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,\n",
       "       18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,\n",
       "       31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,\n",
       "       19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,\n",
       "       22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,\n",
       "       27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,\n",
       "        8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,\n",
       "       19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,\n",
       "       23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,\n",
       "       21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,\n",
       "       17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,\n",
       "       16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,\n",
       "       24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,\n",
       "       13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,\n",
       "       22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,\n",
       "       23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,\n",
       "        7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,\n",
       "        8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,\n",
       "       19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,\n",
       "       19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,\n",
       "       23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,\n",
       "       19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,\n",
       "       23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,\n",
       "       33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,\n",
       "       28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,\n",
       "       24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,\n",
       "       11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c55d240-5838-4bef-9a04-49d6cf6eb5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.80846e+01, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01,\n",
       "        2.72500e+01, 2.90500e+01],\n",
       "       [1.23290e-01, 0.00000e+00, 1.00100e+01, ..., 1.78000e+01,\n",
       "        3.94950e+02, 1.62100e+01],\n",
       "       [5.49700e-02, 0.00000e+00, 5.19000e+00, ..., 2.02000e+01,\n",
       "        3.96900e+02, 9.74000e+00],\n",
       "       ...,\n",
       "       [1.83377e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
       "        3.89610e+02, 1.92000e+00],\n",
       "       [3.58090e-01, 0.00000e+00, 6.20000e+00, ..., 1.74000e+01,\n",
       "        3.91700e+02, 9.71000e+00],\n",
       "       [2.92400e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
       "        2.40160e+02, 9.81000e+00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85730d0d-85f9-4ae1-b205-8c301b466971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.2, 18.8, 19. , 27. , 22.2, 24.5, 31.2, 22.9, 20.5, 23.2, 18.6,\n",
       "       14.5, 17.8, 50. , 20.8, 24.3, 24.2, 19.8, 19.1, 22.7, 12. , 10.2,\n",
       "       20. , 18.5, 20.9, 23. , 27.5, 30.1,  9.5, 22. , 21.2, 14.1, 33.1,\n",
       "       23.4, 20.1,  7.4, 15.4, 23.8, 20.1, 24.5, 33. , 28.4, 14.1, 46.7,\n",
       "       32.5, 29.6, 28.4, 19.8, 20.2, 25. , 35.4, 20.3,  9.7, 14.5, 34.9,\n",
       "       26.6,  7.2, 50. , 32.4, 21.6, 29.8, 13.1, 27.5, 21.2, 23.1, 21.9,\n",
       "       13. , 23.2,  8.1,  5.6, 21.7, 29.6, 19.6,  7. , 26.4, 18.9, 20.9,\n",
       "       28.1, 35.4, 10.2, 24.3, 43.1, 17.6, 15.4, 16.2, 27.1, 21.4, 21.5,\n",
       "       22.4, 25. , 16.6, 18.6, 22. , 42.8, 35.1, 21.5, 36. , 21.9, 24.1,\n",
       "       50. , 26.7, 25. ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f286ac-6143-4232-b7e8-488b4777ff2a",
   "metadata": {},
   "source": [
    "### SO, now because data that's used in training of the neural networks are mostly very unstructured\n",
    "### Imagine a data from images to find pattern in the images so as to classify them\n",
    "### or data from videos\n",
    "### Surely they are so unstructured, and very random\n",
    "### to get the accuracy and prediction somehow right, it will be necessary to use some sort of Processors & Transformers\n",
    "### i.e scikit-learn processor to be able to ensure that the training data and the test data are somewhat uniform. (i.e of same type)\n",
    "### This conformity and uniformity of both data is done before the learning and training process\n",
    "### Think of it like, before you starting test me with examination in school, we need to agree that before the teaching \n",
    "### So, with the agreement, i can followup with the teaching and training to prepare for examination (prediction in this case)\n",
    "### Between that is when the Uniformity and Conformity comes in, the teaching must be uniform with the examination, right?\n",
    "### This process is very important in neural network because all data are quite random, so we have to ensure that thinkings go as expected between the training and testing data\n",
    "\n",
    "## All this process of reaching agreement between Training Data and Testing Data is called PROCESSING from sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "b910e08c-9eef-49a6-a81d-c64c59a6a73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO process the data here\n",
    "scale_x_train = preprocessing.scale(x_train) #THis scale out the x_train data\n",
    "\n",
    "#AFter scaling out, we convert it out to scaler\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "#The StandardScaler wil Standardize features by removing the mean and scaling to unit variance\n",
    "# return like the standdard deviation, mean deviation, \n",
    "# then the fit() Compute the mean and std to be used for later scaling\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "8b8e7eb1-2257-4de3-9cc8-e6340adc8397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next is to scale the x_test\n",
    "scale_x_test = scaler.transform(x_test)\n",
    "# SO, with all of this done, in a nutshell, the trainign data has been normalized with the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "28059e73-715e-4e70-9c30-2fca8157e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets create our model.\n",
    "\n",
    "my_model = Sequential() #Instantaiting the model from sequential\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05d7bd92-66d6-445b-81a4-eaeb6e420a67",
   "metadata": {},
   "source": [
    "## Now lets start adding layers to our model\n",
    "\n",
    "my_model.add(Dense(no_of_features, kernel_initializers, activation)) <br/>\n",
    "\n",
    "In this case, the add method adds a layer instance on top of the layer stack <br/>\n",
    "In this case, dense is the name of a layer, there are several of it. <br/>\n",
    "Here, using it as the input layer of the neural model <br/>\n",
    "The dense takes a parameter which serve as the number of features in the dataset.  <br/>\n",
    "Bcus in most cases, the number of features isn't constant <br/>\n",
    "and even because, in some cases, the dataset isnt even known, we dont see it, since its a neural network that learn by itself, <br/>\n",
    "Then how do we know the number of features??? <br/>\n",
    "Well, while thats the standard, there are other rule of thumb that tells what should be used, maybe 32, maybe 64 <br/>\n",
    "But in this case lets use 64 <br/>\n",
    "no_of_features = 64 <br/>\n",
    "\n",
    "## Adding a layer ##\n",
    "my_model.add(Dense(no_of_features, kernel_initializer = 'normal', activation = )) <br/>\n",
    "kernel_initializer means that, when inputs are coming in in matrixs, its initilize the value of the them, it could be zero, or it could be one <br/>\n",
    "Some possible value for kernel_initializer variable is \"normal\" which is default,  another is 'glorot_uniform' suitable for most cases <br/>\n",
    "Another is 'he_normal' which is effective for deep networks with ReLU activation function (ReLU to be explained later)  <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff81652c-8920-454c-bcd4-303861a91c33",
   "metadata": {},
   "source": [
    "## Another parameter is the activator, which help to determine the kind of inputs should be used or passed to the next neuron. ##\n",
    "After several data are coming in as inputs, in used in the inout layer, the activators check through them and pick which is to be picked depends on the kind of activator that is to be used. <br/>\n",
    "In neural networks, they are like a decision maker for each neuron in the network. \n",
    "it decides whether the neuron should pass information to the next layer of neurons <br/>\n",
    "From the several of this activator, we have the <br/>\n",
    "\n",
    "Sigmoid: Imagine it as a switch that can be either OFF (0) or ON (1). It's good for making yes/no decisions, like whether an email is spam or not. However, it's not great for very deep networks.\n",
    "\n",
    "ReLU (Rectified Linear Unit): Think of it as a light switch that's either OFF (0) or ON (positive number)It set all negative values to Zero and is computationally efficient. . It's the most popular because it's simple and works well in many cases, like recognizing shapes in image ReLU helps mitigate the vanishing gradient problem but can suffer from 'dying Relu' issues when neurons get stuck at Zero during training.\n",
    "\n",
    "Leaky ReLU: Similar to ReLU, but if the light switch is OFF, there's a tiny bit of light (a small positive number). it addresses the dying Relu problems by allowing a small gradient for negative values in deep networks, which helps avoid neurons becoming inactive.\n",
    "\n",
    "ELU (Exponential Linear Unit): Like Leaky ReLU, but the light switch being OFF isn't pitch black; it's a bit brighter helps training even better. it has a non-zero gradient for negative values which can help with convergence and robustness.\n",
    "\n",
    "Tanh (Hyperbolic Tangent): Imagine it like a thermometer that can show temperatures from -1 to 1. It's useful for data centered around zero, like when predicting if a stock will go up or down. though kinde suffers from vanishing gradients.\n",
    "\n",
    "Softmax: This one is like dividing a pie into slices, where each slice shows the probability of something happening (like each slice shows propability of you getting satisfied). It's often used to decide which of many things is most likely, its primarily used in the outlayer for multiclass classification.\n",
    "\n",
    "Swish: think of Swish as a fancy light dimmer switch that works well in many situations but isn't as popular as ReLU. its kinda promising in lots of scenerio, and striking a balance between Relu and sigmoid-like functions.\n",
    "\n",
    "GELU (Gaussian Error Linear Unit): This one is like a special tool used in some situations, like understanding the meaning of words in a sentence. Its used in tranformer-based models and effective in NLP tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c336f7a-9693-4b57-a8ea-0ef0a3ec2bf5",
   "metadata": {},
   "source": [
    "### no_of_features = 64 \n",
    "### This is same as number of neurons\n",
    "\n",
    "## Adding a layer ##\n",
    "### my_model.add(Dense(no_of_features, kernel_initializer = 'normal', activation = 'ReLU' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "9823aa4a-78f6-4b8c-80db-d449df46e70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next after this is to define the input_shape, which is more like the shape of the data, this is quite debatable\n",
    "# we do that with the input_shape paramter to the Dense class we are filling\n",
    "# to have an idea of our data shape we can easily use the .shape method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "e48e9302-e556-4ecf-a5c7-df8bfb6030ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32fbd24-0677-4239-b219-ce4c4ba48ad9",
   "metadata": {},
   "source": [
    "### WHile the shape result doesnt always dictate the value for the input_shape parameter\n",
    "### it could be a factor, so for this use case, i will use 13\n",
    "### Note that there use to be a CV function that could be imported which is specifically used for getting the efficient shape of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "edf72cc7-1aa9-4ad6-9d96-d0d918be155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Adding the input layer ##\n",
    "no_of_features = 64\n",
    "\n",
    "my_model.add(Dense(no_of_features, kernel_initializer = 'normal', activation = 'ReLU', input_shape = (13, )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "e3577a83-96d7-4641-990d-45c7431b2337",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding a hidden layer 1\n",
    "my_model.add(Dense(no_of_features, activation = 'ReLU'))\n",
    "# SO, when creating the new layer, kernel initializer are not needed to be passed\n",
    "# and the input_shape are not needed, thats because the output of the input layer becomes the input of the next hidden layer\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c88caaf-4603-4d63-bedb-2a7216d189bf",
   "metadata": {},
   "source": [
    "It might feel to ask that how many hidden layer are enough after the input layer and before the output layer\n",
    "Well, while the numbers of hidden layer may depend on the problem being solved, we should also consider that in some cases, the neural network are not built for specific problem.\n",
    "Though, what happens behind the scene is that:\n",
    "When there are enough hidden layer, if a problem is being solved\n",
    "There is a function that monitors if the problem is satisfactoryly solve\n",
    "Then it automatically moved the solution to the output layer \n",
    "So, knowning this, there may not be specific value for hidden layer,\n",
    "but being good enough is good, though might require higher resources.\n",
    "at time when accuracy is low, it could be decided to add more hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717896eb-f897-4a5f-971d-b284115407ee",
   "metadata": {},
   "source": [
    "### Because we are building this model from stratch is why we require all of this\n",
    "### there are already built model made avaiable.\n",
    "### EG, the popular ChatGPT uses the transformer model.\n",
    "### And there are always different model built for different purpose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "769f013d-3760-4084-b1fc-e94aca524270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, lets create for more hidden layers\n",
    "\n",
    "## Adding a hidden layer 2\n",
    "my_model.add(Dense(no_of_features, activation = 'ReLU'))\n",
    "\n",
    "\n",
    "## Adding a hidden layer 3\n",
    "my_model.add(Dense(no_of_features, activation = 'ReLU'))\n",
    "\n",
    "\n",
    "## Adding a hidden layer 4\n",
    "my_model.add(Dense(no_of_features, activation = 'ReLU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "f86e98a3-f5ab-426e-affd-c2fa2c7f0ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's add the outer layer\n",
    "\n",
    "\n",
    "## Adding a Outer Layer\n",
    "my_model.add(Dense(1))\n",
    "# For the output model, the no_of_features (i.e no_of_neurons) is mostly 1, especialy for regression models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "6b6cd26d-03a2-4618-bae7-5e5e43984216",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Next is to compile the model\n",
    "### Compiling the model is needed after building the model\n",
    "### We compile by saying\n",
    "\n",
    "my_model.compile(\n",
    "    loss = \"mse\",\n",
    "    optimizer = RMSprop(),\n",
    "    metrics = ['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "4440fadc-c11f-4984-8308-28608511cd0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.03125"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO get the epoch value that will be needed below\n",
    "size = x_train.size\n",
    "\n",
    "size\n",
    "\n",
    "epoch_value = size / 128 #(i.e 5252/128)\n",
    "epoch_value"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e7eb1053-dc82-4a56-bdaf-e4cda1e393ed",
   "metadata": {},
   "source": [
    "\n",
    "# Training the model, just like its done when we were using only sklearn\n",
    "training = my_model.fit(\n",
    "    scale_x_train, #This should be the x train data that has been preprocessed and matched the test data\n",
    "    y_train, # The y train data\n",
    "    batch_size = 128, #This store the number of samples from dataset that wil the trained at same time, normal popular is mostly 128\n",
    "    # SO, lets use 128 also. if batch_size isn't set, its default is 32\n",
    "    epochs = 500, # The number of iterate (i.e runs) the processing should be done is called Epoch\n",
    "    # Epochs could be calculated by size of dataset divided by batch_size (i.e epoch = size / batch_size)\n",
    "    verbose = 1, # OPTIONAL PARAMETER: verbose is the logging level of the training\n",
    "    # It  takes 0, 1 or 2, default is 1, which monitor the training progree\n",
    "    # 0  means does not monitor the training  progress, it \n",
    "    validation_split = 0.2, # This works like dividing the dataset into training and testing,\n",
    "    # If it's 0.3, then means like, 30% is for testing ahile automatically 70% for training\n",
    "    #If it's 0.2, then means like, 20% is for testing ahile automatically 80% for training\n",
    "    callbacks = [EarlyStopping(monitor = 'val_loss', patience = 20)]\n",
    ") \n",
    "Callback paramater for the fit function means to specify when the model should stop sending inputs to the next hidden layer but rather sends it to the output layer if it has already solve the problem and well\n",
    "TO use it, we need to import the EarlyStopping from Keras.callbacks  then use in the syntax above\n",
    "#patience parameter for EarlStopping means how long it should wait to conclude that the input has been solved and can be sent to the output layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "d3f7688c-b1fe-4565-89a7-1d839f5fa9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3/3 [==============================] - 3s 186ms/step - loss: 554.8154 - mean_absolute_error: 21.8934 - val_loss: 628.4691 - val_mean_absolute_error: 22.9245\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 530.7014 - mean_absolute_error: 21.3364 - val_loss: 580.3546 - val_mean_absolute_error: 21.8535\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 479.7946 - mean_absolute_error: 20.0879 - val_loss: 490.3016 - val_mean_absolute_error: 19.7132\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 388.4919 - mean_absolute_error: 17.7262 - val_loss: 357.4829 - val_mean_absolute_error: 16.2884\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 262.3101 - mean_absolute_error: 13.9997 - val_loss: 217.1158 - val_mean_absolute_error: 12.2712\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 142.8768 - mean_absolute_error: 10.0244 - val_loss: 120.4547 - val_mean_absolute_error: 8.3556\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 67.3794 - mean_absolute_error: 6.5896 - val_loss: 78.5840 - val_mean_absolute_error: 6.5411\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 42.5902 - mean_absolute_error: 4.9896 - val_loss: 63.5437 - val_mean_absolute_error: 5.7942\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 34.1320 - mean_absolute_error: 4.3047 - val_loss: 53.8383 - val_mean_absolute_error: 5.2735\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 29.0457 - mean_absolute_error: 3.9503 - val_loss: 47.7575 - val_mean_absolute_error: 5.0828\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 26.4268 - mean_absolute_error: 3.7359 - val_loss: 42.5350 - val_mean_absolute_error: 4.6711\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 23.1160 - mean_absolute_error: 3.5638 - val_loss: 40.2882 - val_mean_absolute_error: 4.6501\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 22.2535 - mean_absolute_error: 3.3385 - val_loss: 35.4909 - val_mean_absolute_error: 4.3017\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 19.4356 - mean_absolute_error: 3.2959 - val_loss: 34.9496 - val_mean_absolute_error: 3.9800\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 17.6582 - mean_absolute_error: 3.0525 - val_loss: 31.7504 - val_mean_absolute_error: 3.9008\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 16.5818 - mean_absolute_error: 2.9943 - val_loss: 34.5480 - val_mean_absolute_error: 3.8882\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 16.0817 - mean_absolute_error: 2.8640 - val_loss: 36.7703 - val_mean_absolute_error: 4.0520\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 18.8631 - mean_absolute_error: 3.2918 - val_loss: 28.2371 - val_mean_absolute_error: 3.6464\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 14.9919 - mean_absolute_error: 2.8020 - val_loss: 29.8703 - val_mean_absolute_error: 3.5310\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 13.9945 - mean_absolute_error: 2.6796 - val_loss: 27.0675 - val_mean_absolute_error: 3.3989\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 12.8559 - mean_absolute_error: 2.5726 - val_loss: 27.2309 - val_mean_absolute_error: 3.8388\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 14.7537 - mean_absolute_error: 2.9484 - val_loss: 22.7215 - val_mean_absolute_error: 3.2901\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 11.8874 - mean_absolute_error: 2.5428 - val_loss: 21.9812 - val_mean_absolute_error: 3.2962\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 11.1668 - mean_absolute_error: 2.4857 - val_loss: 34.0368 - val_mean_absolute_error: 4.0220\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 19.0930 - mean_absolute_error: 3.3451 - val_loss: 27.1724 - val_mean_absolute_error: 3.8933\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 15.1354 - mean_absolute_error: 2.9811 - val_loss: 21.8354 - val_mean_absolute_error: 3.1084\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 10.3052 - mean_absolute_error: 2.3495 - val_loss: 19.6289 - val_mean_absolute_error: 2.9923\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 9.7650 - mean_absolute_error: 2.3451 - val_loss: 21.7064 - val_mean_absolute_error: 3.0178\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 9.9432 - mean_absolute_error: 2.3432 - val_loss: 19.7899 - val_mean_absolute_error: 2.9871\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 9.4499 - mean_absolute_error: 2.1975 - val_loss: 21.3200 - val_mean_absolute_error: 2.9934\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 10.2719 - mean_absolute_error: 2.4206 - val_loss: 24.6201 - val_mean_absolute_error: 3.6083\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 14.5409 - mean_absolute_error: 2.9239 - val_loss: 19.7601 - val_mean_absolute_error: 2.9448\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 8.5273 - mean_absolute_error: 2.1320 - val_loss: 18.8154 - val_mean_absolute_error: 2.8959\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 9.5685 - mean_absolute_error: 2.3356 - val_loss: 21.5534 - val_mean_absolute_error: 3.0414\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 10.6102 - mean_absolute_error: 2.4051 - val_loss: 18.5505 - val_mean_absolute_error: 2.8576\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 8.0078 - mean_absolute_error: 2.0730 - val_loss: 18.1899 - val_mean_absolute_error: 2.7604\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 9.4129 - mean_absolute_error: 2.2388 - val_loss: 23.8131 - val_mean_absolute_error: 3.7411\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 12.0424 - mean_absolute_error: 2.6947 - val_loss: 19.6501 - val_mean_absolute_error: 2.9475\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 8.3528 - mean_absolute_error: 2.1286 - val_loss: 17.9454 - val_mean_absolute_error: 2.8125\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 8.0440 - mean_absolute_error: 2.0831 - val_loss: 18.1635 - val_mean_absolute_error: 2.8639\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 8.4472 - mean_absolute_error: 2.2047 - val_loss: 18.5051 - val_mean_absolute_error: 2.8928\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 7.9585 - mean_absolute_error: 2.1192 - val_loss: 17.8279 - val_mean_absolute_error: 2.8696\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 7.2793 - mean_absolute_error: 2.0085 - val_loss: 20.4732 - val_mean_absolute_error: 3.2800\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 10.1497 - mean_absolute_error: 2.4326 - val_loss: 19.6518 - val_mean_absolute_error: 2.9589\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 8.8330 - mean_absolute_error: 2.2383 - val_loss: 23.0391 - val_mean_absolute_error: 3.6760\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 10.1202 - mean_absolute_error: 2.4200 - val_loss: 16.9607 - val_mean_absolute_error: 2.8843\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 8.2498 - mean_absolute_error: 2.1697 - val_loss: 15.9158 - val_mean_absolute_error: 2.6598\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 7.2528 - mean_absolute_error: 2.0096 - val_loss: 20.2711 - val_mean_absolute_error: 3.3104\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 10.3181 - mean_absolute_error: 2.5762 - val_loss: 17.4172 - val_mean_absolute_error: 2.9518\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 7.2551 - mean_absolute_error: 2.0420 - val_loss: 17.7477 - val_mean_absolute_error: 2.8058\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 6.8183 - mean_absolute_error: 1.9361 - val_loss: 19.1181 - val_mean_absolute_error: 3.2256\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 11.0037 - mean_absolute_error: 2.5880 - val_loss: 16.8867 - val_mean_absolute_error: 2.7641\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 8.1833 - mean_absolute_error: 2.1615 - val_loss: 21.0890 - val_mean_absolute_error: 3.3657\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 9.3191 - mean_absolute_error: 2.3501 - val_loss: 16.2161 - val_mean_absolute_error: 2.6996\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 6.6259 - mean_absolute_error: 1.9235 - val_loss: 18.1412 - val_mean_absolute_error: 2.9061\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 7.0511 - mean_absolute_error: 2.0304 - val_loss: 18.0489 - val_mean_absolute_error: 2.9680\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 7.7758 - mean_absolute_error: 2.0401 - val_loss: 16.4819 - val_mean_absolute_error: 2.7293\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 6.4407 - mean_absolute_error: 1.8889 - val_loss: 19.6141 - val_mean_absolute_error: 3.0228\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 10.1429 - mean_absolute_error: 2.4820 - val_loss: 16.1018 - val_mean_absolute_error: 2.7688\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 7.4562 - mean_absolute_error: 2.0850 - val_loss: 20.4746 - val_mean_absolute_error: 3.1547\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 8.2269 - mean_absolute_error: 2.2136 - val_loss: 15.6769 - val_mean_absolute_error: 2.6450\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 7.0586 - mean_absolute_error: 1.9599 - val_loss: 17.0304 - val_mean_absolute_error: 2.7368\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 7.2915 - mean_absolute_error: 2.0244 - val_loss: 17.6647 - val_mean_absolute_error: 2.9386\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 6.9984 - mean_absolute_error: 2.0243 - val_loss: 16.6901 - val_mean_absolute_error: 2.7174\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 6.2519 - mean_absolute_error: 1.8668 - val_loss: 17.1895 - val_mean_absolute_error: 2.7682\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 7.2606 - mean_absolute_error: 2.1454 - val_loss: 21.5059 - val_mean_absolute_error: 3.3896\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 9.9635 - mean_absolute_error: 2.4545 - val_loss: 19.4845 - val_mean_absolute_error: 3.2099\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 8.4125 - mean_absolute_error: 2.2495 - val_loss: 16.4583 - val_mean_absolute_error: 2.7112\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 6.3886 - mean_absolute_error: 1.9240 - val_loss: 16.3322 - val_mean_absolute_error: 2.7602\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 6.7541 - mean_absolute_error: 1.9583 - val_loss: 17.0422 - val_mean_absolute_error: 2.8782\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 6.7313 - mean_absolute_error: 1.9886 - val_loss: 16.4330 - val_mean_absolute_error: 2.7776\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 5.8036 - mean_absolute_error: 1.7916 - val_loss: 15.4489 - val_mean_absolute_error: 2.6715\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 8.2267 - mean_absolute_error: 2.1901 - val_loss: 23.7612 - val_mean_absolute_error: 3.4868\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 9.1177 - mean_absolute_error: 2.2934 - val_loss: 16.7414 - val_mean_absolute_error: 2.7739\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 5.8691 - mean_absolute_error: 1.7971 - val_loss: 21.4760 - val_mean_absolute_error: 3.1582\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 7.8772 - mean_absolute_error: 2.0875 - val_loss: 16.2140 - val_mean_absolute_error: 2.7351\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 5.7737 - mean_absolute_error: 1.7887 - val_loss: 15.5666 - val_mean_absolute_error: 2.5606\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 5.7610 - mean_absolute_error: 1.7667 - val_loss: 20.8822 - val_mean_absolute_error: 3.4518\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 10.7558 - mean_absolute_error: 2.6765 - val_loss: 18.1724 - val_mean_absolute_error: 2.9383\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 7.0556 - mean_absolute_error: 2.0054 - val_loss: 16.3523 - val_mean_absolute_error: 2.6765\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 6.4477 - mean_absolute_error: 1.9159 - val_loss: 16.7526 - val_mean_absolute_error: 2.8882\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 6.3608 - mean_absolute_error: 1.8844 - val_loss: 19.1980 - val_mean_absolute_error: 2.9394\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 6.7536 - mean_absolute_error: 1.9398 - val_loss: 18.4474 - val_mean_absolute_error: 3.0700\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 8.0607 - mean_absolute_error: 2.1583 - val_loss: 16.2506 - val_mean_absolute_error: 2.6724\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 5.8733 - mean_absolute_error: 1.8460 - val_loss: 15.6190 - val_mean_absolute_error: 2.6186\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 5.5514 - mean_absolute_error: 1.7614 - val_loss: 15.4288 - val_mean_absolute_error: 2.6274\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 5.2235 - mean_absolute_error: 1.6790 - val_loss: 20.2373 - val_mean_absolute_error: 3.3222\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 8.8118 - mean_absolute_error: 2.3370 - val_loss: 15.8769 - val_mean_absolute_error: 2.6419\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 5.1156 - mean_absolute_error: 1.6635 - val_loss: 15.6607 - val_mean_absolute_error: 2.6840\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 7.1266 - mean_absolute_error: 2.0107 - val_loss: 16.7346 - val_mean_absolute_error: 2.7804\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 7.3495 - mean_absolute_error: 2.0655 - val_loss: 18.2383 - val_mean_absolute_error: 3.0851\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 8.0837 - mean_absolute_error: 2.1507 - val_loss: 16.1644 - val_mean_absolute_error: 2.7081\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 6.0818 - mean_absolute_error: 1.8857 - val_loss: 15.9572 - val_mean_absolute_error: 2.7305\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 5.5491 - mean_absolute_error: 1.7355 - val_loss: 17.4000 - val_mean_absolute_error: 2.8004\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 6.3881 - mean_absolute_error: 1.9024 - val_loss: 20.9403 - val_mean_absolute_error: 3.5023\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 9.6838 - mean_absolute_error: 2.4752 - val_loss: 21.6215 - val_mean_absolute_error: 3.3710\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 7.8558 - mean_absolute_error: 2.1154 - val_loss: 15.8499 - val_mean_absolute_error: 2.7427\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 5.6602 - mean_absolute_error: 1.8117 - val_loss: 16.3291 - val_mean_absolute_error: 2.7282\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 5.8484 - mean_absolute_error: 1.8456 - val_loss: 16.3349 - val_mean_absolute_error: 2.8259\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 5.6313 - mean_absolute_error: 1.7783 - val_loss: 15.3169 - val_mean_absolute_error: 2.5779\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 5.6584 - mean_absolute_error: 1.7484 - val_loss: 15.6262 - val_mean_absolute_error: 2.6266\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.7722 - mean_absolute_error: 1.5901 - val_loss: 18.8706 - val_mean_absolute_error: 3.1072\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 8.6281 - mean_absolute_error: 2.2911 - val_loss: 15.1644 - val_mean_absolute_error: 2.6643\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 5.3432 - mean_absolute_error: 1.6877 - val_loss: 17.9887 - val_mean_absolute_error: 2.9562\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 10.3220 - mean_absolute_error: 2.5730 - val_loss: 15.0404 - val_mean_absolute_error: 2.5362\n",
      "Epoch 106/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 4.6787 - mean_absolute_error: 1.5831 - val_loss: 15.3426 - val_mean_absolute_error: 2.6433\n",
      "Epoch 107/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 5.1189 - mean_absolute_error: 1.6216 - val_loss: 14.4264 - val_mean_absolute_error: 2.4559\n",
      "Epoch 108/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.5637 - mean_absolute_error: 1.5478 - val_loss: 17.0317 - val_mean_absolute_error: 2.7747\n",
      "Epoch 109/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 6.5172 - mean_absolute_error: 1.9682 - val_loss: 23.6733 - val_mean_absolute_error: 3.7026\n",
      "Epoch 110/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 10.3479 - mean_absolute_error: 2.4745 - val_loss: 15.3284 - val_mean_absolute_error: 2.5755\n",
      "Epoch 111/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 4.5273 - mean_absolute_error: 1.5547 - val_loss: 15.4274 - val_mean_absolute_error: 2.6213\n",
      "Epoch 112/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 4.7362 - mean_absolute_error: 1.5906 - val_loss: 20.5782 - val_mean_absolute_error: 3.3642\n",
      "Epoch 113/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 9.1370 - mean_absolute_error: 2.3930 - val_loss: 14.8155 - val_mean_absolute_error: 2.5765\n",
      "Epoch 114/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 4.6165 - mean_absolute_error: 1.5630 - val_loss: 16.4830 - val_mean_absolute_error: 2.7999\n",
      "Epoch 115/500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 6.8420 - mean_absolute_error: 1.9472 - val_loss: 17.5558 - val_mean_absolute_error: 2.8308\n",
      "Epoch 116/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 5.1622 - mean_absolute_error: 1.5928 - val_loss: 16.1968 - val_mean_absolute_error: 2.7164\n",
      "Epoch 117/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 6.0054 - mean_absolute_error: 1.7985 - val_loss: 20.9998 - val_mean_absolute_error: 3.5183\n",
      "Epoch 118/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 9.2001 - mean_absolute_error: 2.4417 - val_loss: 15.9699 - val_mean_absolute_error: 2.7085\n",
      "Epoch 119/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 5.6432 - mean_absolute_error: 1.7646 - val_loss: 16.7842 - val_mean_absolute_error: 2.8741\n",
      "Epoch 120/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 5.3982 - mean_absolute_error: 1.7326 - val_loss: 19.2642 - val_mean_absolute_error: 3.0121\n",
      "Epoch 121/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 8.4568 - mean_absolute_error: 2.2420 - val_loss: 15.0438 - val_mean_absolute_error: 2.5484\n",
      "Epoch 122/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 4.3729 - mean_absolute_error: 1.5104 - val_loss: 15.7012 - val_mean_absolute_error: 2.7394\n",
      "Epoch 123/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 6.7692 - mean_absolute_error: 1.9812 - val_loss: 17.1021 - val_mean_absolute_error: 2.8375\n",
      "Epoch 124/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 5.0466 - mean_absolute_error: 1.6822 - val_loss: 14.8993 - val_mean_absolute_error: 2.5342\n",
      "Epoch 125/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 5.3658 - mean_absolute_error: 1.6854 - val_loss: 25.9722 - val_mean_absolute_error: 3.8868\n",
      "Epoch 126/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 9.4359 - mean_absolute_error: 2.3724 - val_loss: 14.4924 - val_mean_absolute_error: 2.4843\n",
      "Epoch 127/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.2553 - mean_absolute_error: 1.5199 - val_loss: 14.7281 - val_mean_absolute_error: 2.5727\n"
     ]
    }
   ],
   "source": [
    "# Training the model, just like its done when we were using only sklearn\n",
    "training = my_model.fit(\n",
    "    scale_x_train,\n",
    "    y_train, \n",
    "    batch_size = 128,\n",
    "    epochs = 500,\n",
    "    verbose = 1, \n",
    "    validation_split = 0.3,\n",
    "    callbacks = [EarlyStopping(monitor = 'val_loss', patience = 20)]\n",
    ")\n",
    "\n",
    "# After running this, we need to take note that the value for the loss is reducing and also, the mean_absolute_error value is reducing\n",
    "# with that it tells that the model is learning properly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dcb007-a06c-462a-9065-56f1303245d3",
   "metadata": {},
   "source": [
    "### wew now, i notice that the loss function reduced enough, the mean_absolute_error reduced enough and then all othe reduced\n",
    "### that shows that the model learned properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "10ee6efe-b44e-459b-9dba-83396a5fa486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 20.0036 - mean_absolute_error: 2.8219\n"
     ]
    }
   ],
   "source": [
    "# Next is to evaluate the model\n",
    "score = my_model.evaluate(scale_x_test, y_test, verbose = 1)\n",
    "# notice here that the x parameter takes the x_test thats has been scaled to fit the condiions as explained earlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "ce7698fc-bcf2-4997-b1a7-de9459561d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20.00362205505371, 2.821911096572876]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score\n",
    "#This echos a list with 2 parameters, first is the loss function value, while the other is the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "301eb27c-46c5-4dee-81f0-6d2f793b47f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is  20.00362205505371\n"
     ]
    }
   ],
   "source": [
    "print('Loss is ', score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "c640a4f2-941b-4587-8f77-593d3eb8de67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  2.821911096572876\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy is ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "799c6dd4-0f03-4bf9-af2f-aa2071486c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# Now, lets use the model to predict\n",
    "prediction = my_model.predict(scale_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "0b12dc9d-035d-46e3-b438-a5525a178e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.267683]\n",
      " [19.410322]\n",
      " [21.261454]\n",
      " [32.76542 ]\n",
      " [24.711634]\n",
      " [20.653315]\n",
      " [28.284483]\n",
      " [21.925129]\n",
      " [19.529306]\n",
      " [22.026274]\n",
      " [21.057598]\n",
      " [17.481157]\n",
      " [15.525068]\n",
      " [42.62654 ]\n",
      " [19.228777]\n",
      " [20.628086]\n",
      " [26.632254]\n",
      " [21.949602]\n",
      " [19.003141]\n",
      " [32.275673]\n",
      " [12.194963]\n",
      " [15.413172]\n",
      " [21.319895]\n",
      " [15.512399]\n",
      " [21.4462  ]\n",
      " [25.195448]\n",
      " [30.239496]\n",
      " [30.693674]\n",
      " [11.966005]\n",
      " [21.668056]\n",
      " [20.14115 ]\n",
      " [15.627238]\n",
      " [33.7219  ]\n",
      " [25.25649 ]\n",
      " [17.949846]\n",
      " [ 8.55629 ]\n",
      " [15.518869]\n",
      " [18.209648]\n",
      " [19.979757]\n",
      " [26.755526]\n",
      " [31.623613]\n",
      " [27.566229]\n",
      " [13.603601]\n",
      " [41.98044 ]\n",
      " [29.118288]\n",
      " [24.391594]\n",
      " [26.566332]\n",
      " [17.27186 ]\n",
      " [22.681095]\n",
      " [22.555632]\n",
      " [35.70888 ]\n",
      " [21.03267 ]\n",
      " [11.602504]\n",
      " [14.940475]\n",
      " [36.153282]\n",
      " [28.07739 ]\n",
      " [12.998335]\n",
      " [49.202347]\n",
      " [34.531685]\n",
      " [24.957127]\n",
      " [24.672512]\n",
      " [16.381437]\n",
      " [15.178102]\n",
      " [19.453741]\n",
      " [23.899685]\n",
      " [22.357323]\n",
      " [12.75062 ]\n",
      " [22.86074 ]\n",
      " [12.403351]\n",
      " [ 8.742179]\n",
      " [32.292885]\n",
      " [30.6063  ]\n",
      " [25.57156 ]\n",
      " [12.529413]\n",
      " [26.472795]\n",
      " [20.634462]\n",
      " [20.898458]\n",
      " [23.930754]\n",
      " [35.428234]\n",
      " [10.678164]\n",
      " [20.997519]\n",
      " [38.15942 ]\n",
      " [16.69275 ]\n",
      " [12.756891]\n",
      " [18.768776]\n",
      " [20.099869]\n",
      " [19.518496]\n",
      " [22.699247]\n",
      " [22.475782]\n",
      " [30.510012]\n",
      " [19.573603]\n",
      " [20.835999]\n",
      " [26.994799]\n",
      " [44.099907]\n",
      " [35.46499 ]\n",
      " [19.511875]\n",
      " [35.482716]\n",
      " [51.101418]\n",
      " [27.220102]\n",
      " [46.665134]\n",
      " [31.435328]\n",
      " [20.54371 ]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "8dbdfe29-325a-4873-8b4c-0c4dbbe8c729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.267683, 19.410322, 21.261454, 32.76542 , 24.711634, 20.653315,\n",
       "       28.284483, 21.925129, 19.529306, 22.026274, 21.057598, 17.481157,\n",
       "       15.525068, 42.62654 , 19.228777, 20.628086, 26.632254, 21.949602,\n",
       "       19.003141, 32.275673, 12.194963, 15.413172, 21.319895, 15.512399,\n",
       "       21.4462  , 25.195448, 30.239496, 30.693674, 11.966005, 21.668056,\n",
       "       20.14115 , 15.627238, 33.7219  , 25.25649 , 17.949846,  8.55629 ,\n",
       "       15.518869, 18.209648, 19.979757, 26.755526, 31.623613, 27.566229,\n",
       "       13.603601, 41.98044 , 29.118288, 24.391594, 26.566332, 17.27186 ,\n",
       "       22.681095, 22.555632, 35.70888 , 21.03267 , 11.602504, 14.940475,\n",
       "       36.153282, 28.07739 , 12.998335, 49.202347, 34.531685, 24.957127,\n",
       "       24.672512, 16.381437, 15.178102, 19.453741, 23.899685, 22.357323,\n",
       "       12.75062 , 22.86074 , 12.403351,  8.742179, 32.292885, 30.6063  ,\n",
       "       25.57156 , 12.529413, 26.472795, 20.634462, 20.898458, 23.930754,\n",
       "       35.428234, 10.678164, 20.997519, 38.15942 , 16.69275 , 12.756891,\n",
       "       18.768776, 20.099869, 19.518496, 22.699247, 22.475782, 30.510012,\n",
       "       19.573603, 20.835999, 26.994799, 44.099907, 35.46499 , 19.511875,\n",
       "       35.482716, 51.101418, 27.220102, 46.665134, 31.435328, 20.54371 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the prediction look long, lets flatten it\n",
    "\n",
    "predicted_data = prediction.flatten() #Stored the predicted value to a variable\n",
    "predicted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "a8922537-ceaf-4024-85fe-a272655b0f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.2, 18.8, 19. , 27. , 22.2, 24.5, 31.2, 22.9, 20.5, 23.2, 18.6,\n",
       "       14.5, 17.8, 50. , 20.8, 24.3, 24.2, 19.8, 19.1, 22.7, 12. , 10.2,\n",
       "       20. , 18.5, 20.9, 23. , 27.5, 30.1,  9.5, 22. , 21.2, 14.1, 33.1,\n",
       "       23.4, 20.1,  7.4, 15.4, 23.8, 20.1, 24.5, 33. , 28.4, 14.1, 46.7,\n",
       "       32.5, 29.6, 28.4, 19.8, 20.2, 25. , 35.4, 20.3,  9.7, 14.5, 34.9,\n",
       "       26.6,  7.2, 50. , 32.4, 21.6, 29.8, 13.1, 27.5, 21.2, 23.1, 21.9,\n",
       "       13. , 23.2,  8.1,  5.6, 21.7, 29.6, 19.6,  7. , 26.4, 18.9, 20.9,\n",
       "       28.1, 35.4, 10.2, 24.3, 43.1, 17.6, 15.4, 16.2, 27.1, 21.4, 21.5,\n",
       "       22.4, 25. , 16.6, 18.6, 22. , 42.8, 35.1, 21.5, 36. , 21.9, 24.1,\n",
       "       50. , 26.7, 25. ])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_data = y_test\n",
    "y_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "792c5702-a35d-483d-805e-ec0aa808f2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "below is the value and predicted value caomparing both of them\n",
      "original value from test data === 18.8, Predicted value === 19.410322189331055\n",
      "original value from test data === 19.0, Predicted value === 21.26145362854004\n",
      "original value from test data === 27.0, Predicted value === 32.765419006347656\n",
      "original value from test data === 22.2, Predicted value === 24.711633682250977\n",
      "original value from test data === 24.5, Predicted value === 20.6533145904541\n",
      "original value from test data === 31.2, Predicted value === 28.284482955932617\n",
      "original value from test data === 22.9, Predicted value === 21.925128936767578\n",
      "original value from test data === 20.5, Predicted value === 19.529306411743164\n",
      "original value from test data === 23.2, Predicted value === 22.026273727416992\n",
      "original value from test data === 18.6, Predicted value === 21.057598114013672\n",
      "original value from test data === 14.5, Predicted value === 17.481157302856445\n",
      "original value from test data === 17.8, Predicted value === 15.525068283081055\n",
      "original value from test data === 50.0, Predicted value === 42.62654113769531\n",
      "original value from test data === 20.8, Predicted value === 19.228776931762695\n",
      "original value from test data === 24.3, Predicted value === 20.62808609008789\n",
      "original value from test data === 24.2, Predicted value === 26.632253646850586\n",
      "original value from test data === 19.8, Predicted value === 21.949602127075195\n",
      "original value from test data === 19.1, Predicted value === 19.003141403198242\n",
      "original value from test data === 22.7, Predicted value === 32.275672912597656\n",
      "original value from test data === 12.0, Predicted value === 12.194963455200195\n",
      "original value from test data === 10.2, Predicted value === 15.413171768188477\n",
      "original value from test data === 20.0, Predicted value === 21.319894790649414\n",
      "original value from test data === 18.5, Predicted value === 15.512398719787598\n",
      "original value from test data === 20.9, Predicted value === 21.446199417114258\n",
      "original value from test data === 23.0, Predicted value === 25.19544792175293\n",
      "original value from test data === 27.5, Predicted value === 30.2394962310791\n",
      "original value from test data === 30.1, Predicted value === 30.693674087524414\n",
      "original value from test data === 9.5, Predicted value === 11.966005325317383\n",
      "original value from test data === 22.0, Predicted value === 21.66805648803711\n",
      "original value from test data === 21.2, Predicted value === 20.141149520874023\n",
      "original value from test data === 14.1, Predicted value === 15.627238273620605\n",
      "original value from test data === 33.1, Predicted value === 33.721900939941406\n",
      "original value from test data === 23.4, Predicted value === 25.25649070739746\n",
      "original value from test data === 20.1, Predicted value === 17.949846267700195\n",
      "original value from test data === 7.4, Predicted value === 8.556289672851562\n",
      "original value from test data === 15.4, Predicted value === 15.518869400024414\n",
      "original value from test data === 23.8, Predicted value === 18.20964813232422\n",
      "original value from test data === 20.1, Predicted value === 19.97975730895996\n",
      "original value from test data === 24.5, Predicted value === 26.755525588989258\n",
      "original value from test data === 33.0, Predicted value === 31.623613357543945\n",
      "original value from test data === 28.4, Predicted value === 27.56622886657715\n",
      "original value from test data === 14.1, Predicted value === 13.603601455688477\n",
      "original value from test data === 46.7, Predicted value === 41.980438232421875\n",
      "original value from test data === 32.5, Predicted value === 29.118288040161133\n",
      "original value from test data === 29.6, Predicted value === 24.39159393310547\n",
      "original value from test data === 28.4, Predicted value === 26.56633186340332\n",
      "original value from test data === 19.8, Predicted value === 17.271860122680664\n",
      "original value from test data === 20.2, Predicted value === 22.681095123291016\n",
      "original value from test data === 25.0, Predicted value === 22.555631637573242\n",
      "original value from test data === 35.4, Predicted value === 35.70888137817383\n",
      "original value from test data === 20.3, Predicted value === 21.032669067382812\n",
      "original value from test data === 9.7, Predicted value === 11.602503776550293\n",
      "original value from test data === 14.5, Predicted value === 14.940475463867188\n",
      "original value from test data === 34.9, Predicted value === 36.153282165527344\n",
      "original value from test data === 26.6, Predicted value === 28.077390670776367\n",
      "original value from test data === 7.2, Predicted value === 12.998334884643555\n",
      "original value from test data === 50.0, Predicted value === 49.20234680175781\n",
      "original value from test data === 32.4, Predicted value === 34.53168487548828\n",
      "original value from test data === 21.6, Predicted value === 24.95712661743164\n",
      "original value from test data === 29.8, Predicted value === 24.67251205444336\n",
      "original value from test data === 13.1, Predicted value === 16.381437301635742\n",
      "original value from test data === 27.5, Predicted value === 15.178101539611816\n",
      "original value from test data === 21.2, Predicted value === 19.4537410736084\n",
      "original value from test data === 23.1, Predicted value === 23.89968490600586\n",
      "original value from test data === 21.9, Predicted value === 22.357322692871094\n",
      "original value from test data === 13.0, Predicted value === 12.750619888305664\n",
      "original value from test data === 23.2, Predicted value === 22.860740661621094\n",
      "original value from test data === 8.1, Predicted value === 12.403350830078125\n",
      "original value from test data === 5.6, Predicted value === 8.742178916931152\n",
      "original value from test data === 21.7, Predicted value === 32.292884826660156\n",
      "original value from test data === 29.6, Predicted value === 30.606300354003906\n",
      "original value from test data === 19.6, Predicted value === 25.57155990600586\n",
      "original value from test data === 7.0, Predicted value === 12.529413223266602\n",
      "original value from test data === 26.4, Predicted value === 26.472795486450195\n",
      "original value from test data === 18.9, Predicted value === 20.634462356567383\n",
      "original value from test data === 20.9, Predicted value === 20.89845848083496\n",
      "original value from test data === 28.1, Predicted value === 23.930753707885742\n",
      "original value from test data === 35.4, Predicted value === 35.4282341003418\n",
      "original value from test data === 10.2, Predicted value === 10.678163528442383\n",
      "original value from test data === 24.3, Predicted value === 20.99751853942871\n",
      "original value from test data === 43.1, Predicted value === 38.159420013427734\n",
      "original value from test data === 17.6, Predicted value === 16.692750930786133\n",
      "original value from test data === 15.4, Predicted value === 12.756891250610352\n",
      "original value from test data === 16.2, Predicted value === 18.768775939941406\n",
      "original value from test data === 27.1, Predicted value === 20.099868774414062\n",
      "original value from test data === 21.4, Predicted value === 19.518495559692383\n",
      "original value from test data === 21.5, Predicted value === 22.699247360229492\n",
      "original value from test data === 22.4, Predicted value === 22.47578239440918\n",
      "original value from test data === 25.0, Predicted value === 30.510011672973633\n",
      "original value from test data === 16.6, Predicted value === 19.5736026763916\n",
      "original value from test data === 18.6, Predicted value === 20.83599853515625\n",
      "original value from test data === 22.0, Predicted value === 26.99479866027832\n",
      "original value from test data === 42.8, Predicted value === 44.09990692138672\n",
      "original value from test data === 35.1, Predicted value === 35.464988708496094\n",
      "original value from test data === 21.5, Predicted value === 19.51187515258789\n",
      "original value from test data === 36.0, Predicted value === 35.48271560668945\n",
      "original value from test data === 21.9, Predicted value === 51.101417541503906\n",
      "original value from test data === 24.1, Predicted value === 27.220102310180664\n",
      "original value from test data === 50.0, Predicted value === 46.66513442993164\n",
      "original value from test data === 26.7, Predicted value === 31.435327529907227\n",
      "original value from test data === 25.0, Predicted value === 20.543710708618164\n"
     ]
    }
   ],
   "source": [
    "#Now to see what we have predicted, we compare the predicted value with the original set test data value\n",
    "\n",
    "print('below is the value and predicted value caomparing both of them')\n",
    "for x in range(1,len(y_test_data)):\n",
    "    print(f'original value from test data === {y_test_data[x]}, Predicted value === {predicted_data[x]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b47c3c8-fd31-410e-8edc-2343a7826033",
   "metadata": {},
   "source": [
    "# From this, it shows that most of the predicted are close and that tell that the model is pretty fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e9020-2c92-4a11-bcd1-f515e68b5696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
